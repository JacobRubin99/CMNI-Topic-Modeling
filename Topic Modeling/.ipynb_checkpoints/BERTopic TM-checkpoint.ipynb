{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a728f8d5-27c9-42f2-a711-7b02ed583c41",
   "metadata": {},
   "source": [
    "# BERT Topic Modeling of Survey Measurements of Masculinity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1c348a-b853-46d7-98fc-fb07a12c71d2",
   "metadata": {},
   "source": [
    "Purpose: Employ BERT, a topic modeling algorithm, to automatically cluster text data into particular topics. In this particular example, I am analyzing the common topics/themes of ~500 survey questions from surveys that measure masculinity. \n",
    "\n",
    "Topic Modeling Information: https://maartengr.github.io/BERTopic/index.html\n",
    "\n",
    "Inspiration: https://github.com/pinecone-io/examples/tree/master/learn/experimental/algos-and-libraries/bertopic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d7f78f-e263-4adf-9a85-1c8c2d9b246e",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "96d9729d-2c04-4576-9934-82a9c9eb551b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%run Functions/Functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e01834a6-0325-4e3b-b826-1c57847b5e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(94, 7)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../Data/Questions_Final.csv')\n",
    "\n",
    "# Comment the following line if evaluating more than the CMNI\n",
    "df = df[df[\"Scale\"] == \"Conformity to Masculine Norms Inventory\"]\n",
    "\n",
    "print(df.shape)\n",
    "# Put questions in a list\n",
    "docs = df['Question Text'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88343fd-d669-4afd-bcd6-4789ac997c3e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Naive BERTopic (default hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe43045-3412-408b-8106-c8f415bee75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive vectorizer to remove stop words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "topic_model = BERTopic(vectorizer_model=vectorizer_model, nr_topics='auto')\n",
    "# fit model\n",
    "topics, probs = topic_model.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3245698f-a475-4fe3-ae9f-43cca2772560",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topic_info_df = topic_model.get_topic_info()\n",
    "topic_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b702f1b1-bc6b-4cdd-b094-5edeb91aa93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_chart = topic_model.visualize_barchart()\n",
    "\n",
    "# Update filepath as needed\n",
    "bar_chart.write_image(\"../Visualizations/BERTopic_Bar_Chart.png\", width=800, height=600)\n",
    "bar_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd41ed68-cee0-4732-b7a5-883744a5b227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Topics\n",
    "# intertopic_map = model.visualize_topics().show()\n",
    "# heat_map = topic_model.visualize_heatmap()\n",
    "\n",
    "# # Update filepath as needed to save\n",
    "# heat_map.write_image(\"../Visualizations/BERTopic_Heat_Map.png\", width=800, height=600)\n",
    "# heat_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ace4989-38b2-479e-9566-25ee9386a33b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Investigate Factor Loadings of Original CMNI vs. BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cbcf40-bb28-4971-a58e-41be216bf55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get cluster assignments of BERTopic and then merge into dataset\n",
    "full_BERTopic_info = topic_model.get_document_info(docs)\n",
    "\n",
    "# Join the \"Document\" column of full_BERTopic_info with the \"Question Text\" column of df\n",
    "merged_df = pd.merge(df, full_BERTopic_info, left_on=\"Question Text\", right_on=\"Document\", how=\"inner\")\n",
    "\n",
    "# Drop the duplicate \"Document\" column if needed\n",
    "merged_df.drop(\"Document\", axis=1, inplace=True)\n",
    "\n",
    "merged_df_subset = merged_df[[\"Factor\", \"Question Text\", \"Topic\", \"Name\"]]\n",
    "# Rename columns for readability\n",
    "merged_df_subset = merged_df_subset.rename(columns={\n",
    "    \"Question Text\": \"Document\",\n",
    "    \"Factor\": \"Original Factor\",\n",
    "    \"Topic\": \"BERTopic Topic\",\n",
    "    \"Name\": \"BERTopic Name\"\n",
    "})\n",
    "\n",
    "merged_df_subset = merged_df_subset[['Document', 'Original Factor', 'BERTopic Topic', 'BERTopic Name']]\n",
    "merged_df_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2ae9ce-f8e9-4695-bdcb-f830e7619015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cross-tabulation table to count the frequency of occurrences of each combination of \"Original Factor\" and \"BERTopic Topic\".\n",
    "cross_tab = pd.crosstab(merged_df_subset[\"Original Factor\"], merged_df_subset[\"BERTopic Topic\"])\n",
    "\n",
    "# Heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(cross_tab, cmap=\"Blues\", annot=True, fmt=\"d\")\n",
    "plt.title(\"Cross-Tabulation of Original Factors and BERTopic Topics\")\n",
    "plt.xlabel(\"BERTopic Topics\")\n",
    "plt.ylabel(\"Original Factors\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../Visualizations/BERTopic_CrossTab.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665aa6da-fd0f-467d-9e7f-e17cac508290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform chi-squared test of independence to determine whether there is a stat. sig. assoc. \n",
    "# to see whether obs. freqs. in the contingency table differ significantly.\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Convert text values to categorical variables\n",
    "merged_df_subset[\"Original Factor\"] = pd.Categorical(merged_df_subset[\"Original Factor\"])\n",
    "merged_df_subset[\"BERTopic Topic\"] = pd.Categorical(merged_df_subset[\"BERTopic Topic\"])\n",
    "\n",
    "# Create a contingency table\n",
    "contingency_table = pd.crosstab(merged_df_subset[\"Original Factor\"], merged_df_subset[\"BERTopic Topic\"])\n",
    "\n",
    "chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "print(\"Chi-squared statistic:\", chi2)\n",
    "print(\"P-value:\", p_value)\n",
    "print(\"Degrees of freedom:\", dof)\n",
    "print(\"Expected frequencies table:\")\n",
    "print(expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2cfaeb-9d99-43da-b226-9e9d360ea140",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## How does BERTopic work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5ff839-3398-4782-9857-5dbfca5917b7",
   "metadata": {},
   "source": [
    "**Data -> Sentence Embeddings** (transforming text into machine readable version - usually 768/384 dimensions)\n",
    "\n",
    "\n",
    "Sentence Embeddings via Transformers Architecture\n",
    "    Transformers use an encode/decode network. English into a context vector and then decoded. However the context vector is so complex this creates a bottleneck into the decoder. So the attention mechanism tells which decoder parts to focus on. In 2017, attention paper released that found they can remove the recurrent parts of the network and just keep the attention mechanism so high-performing. (called a transformer).\n",
    "\n",
    "New attention (transformer): \n",
    "(1) have positional encoding (sense of order of the tokens)\n",
    "(2) self-attention (how a word is applied to all other words in the sentence). Rather than embed the meaning of the individual word, it embeds the context of the words around it.\n",
    "(3) multi-head attention (parallelization)\n",
    "\n",
    "We can take a pre-trained core (e.g. BERT) and can fine-tune it.\n",
    "\n",
    "So now we have a vector with 768/384 dimensions.\n",
    "\n",
    "    \n",
    "**Embeddings -> UMAP** (dimensionality reduction)\n",
    "\n",
    "UMAP helps us compress embeddings into a smaller vector small (2 or 3 dimensions).\n",
    "Understands density of particular areas in the data through k_nearest_neighbors. Understands distance between different vector rows\n",
    "\n",
    "\n",
    "**UMAP -> clustering with HDBSCAN**\n",
    "Here we can define the number of points needed to define a cluster. (by default something like 5)\n",
    "\n",
    "(Number of topics can be determined by how we set parameters like min_cluster_size and min_samples (how dense the core of a cluster needs to be to group))\n",
    "\n",
    "**clustering with HDBSCAN -> C-TF-IDF**\n",
    "Looks at freq. of words with a particular cluster, and see how common these words are.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf43649-1fe6-4610-b197-fb5090431320",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Customizing BERTopic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bcaa2d-68b1-4d3c-8ff2-231b8d857ea1",
   "metadata": {},
   "source": [
    "Inspiration: https://www.pinecone.io/learn/bertopic/\n",
    "\n",
    "For information on the meaning of parameters, look up the Functions.ipynb file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99449033-718f-4279-a1b2-c202059721b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = df['Question Text'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fedc1e1-11a1-4e4a-ab0f-c2fba0406863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining embedding_model and vectorizer_model outside the run_custom_BERTopic function as they are required for evaluation metrics as well\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Most popular model - Hugging Face: https://huggingface.co/sentence-transformers?sort_models=downloads#models\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# remove stopwords/stop phrases containing 1 and 2 words\n",
    "# NGRAM_RANGE is an important choice\n",
    "stop_words = list(stopwords.words('english'))\n",
    "vectorizer_model = CountVectorizer(ngram_range=(1, 2), stop_words=stop_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bb5683fe-17eb-4f5c-870c-e6361dc8f01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-28 01:35:29,515 - BERTopic - Embedding - Transforming documents to embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade4a61630724af7a155e82837ddbcbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-28 01:35:29,648 - BERTopic - Embedding - Completed ✓\n",
      "2024-05-28 01:35:29,648 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2024-05-28 01:35:30,132 - BERTopic - Dimensionality - Completed ✓\n",
      "2024-05-28 01:35:30,133 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2024-05-28 01:35:30,140 - BERTopic - Cluster - Completed ✓\n",
      "2024-05-28 01:35:30,141 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2024-05-28 01:35:30,152 - BERTopic - Representation - Completed ✓\n"
     ]
    }
   ],
   "source": [
    "# Run custom model\n",
    "model = run_custom_BERTopic(docs, embedding_model, vectorizer_model, min_cluster_size=2, min_samples=1)\n",
    "#model = run_custom_BERTopic(docs, embedding_model, vectorizer_model, min_cluster_size=10, min_samples=10)\n",
    "topics, probs = model.fit_transform(docs)\n",
    "\n",
    "topic_info_df = model.get_topic_info()\n",
    "\n",
    "num_topics = len(topic_info_df) - 1 # DOES NOT INCLUDE OUTLIERS TOPIC. ONLY COHERENT TOPICS\n",
    "#topic_info_df\n",
    "\n",
    "# Visualize Topics\n",
    "# model.visualize_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6ca7e5-8d8d-439f-80e0-4b9ecf176ca5",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a0e7ed07-6975-41fd-a5fe-66847e927739",
   "metadata": {},
   "outputs": [],
   "source": [
    "### GET FULL BERTopic INFO\n",
    "\n",
    "full_BERTopic_info = model.get_document_info(docs)\n",
    "\n",
    "# Join the \"Document\" column of full_BERTopic_info with the \"Question Text\" column of df\n",
    "merged_df = pd.merge(df, full_BERTopic_info, left_on=\"Question Text\", right_on=\"Document\", how=\"inner\")\n",
    "\n",
    "# Drop the duplicate \"Document\" column if needed\n",
    "merged_df.drop(\"Document\", axis=1, inplace=True)\n",
    "\n",
    "merged_df_subset = merged_df[[\"Factor\", \"Question Text\", \"Topic\", \"Name\"]]\n",
    "# Rename columns for readability\n",
    "merged_df_subset = merged_df_subset.rename(columns={\n",
    "    \"Question Text\": \"Document\",\n",
    "    \"Factor\": \"Original Factor\",\n",
    "    \"Topic\": \"BERTopic Topic\",\n",
    "    \"Name\": \"BERTopic Name\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "396c0689-7f5f-4677-a5bb-21ae6c3256d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coherence (NPMI)</th>\n",
       "      <th>Silhouette Score</th>\n",
       "      <th>ARI</th>\n",
       "      <th>Purity</th>\n",
       "      <th>NMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model 1</th>\n",
       "      <td>0.260278</td>\n",
       "      <td>0.636757</td>\n",
       "      <td>0.296786</td>\n",
       "      <td>0.882979</td>\n",
       "      <td>0.739788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Coherence (NPMI)  Silhouette Score       ARI    Purity       NMI\n",
       "model 1          0.260278          0.636757  0.296786  0.882979  0.739788"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Gather evaluation metrics\n",
    "\n",
    "# Create an empty DataFrame with columns for the metrics\n",
    "metrics_df = pd.DataFrame(columns=['Coherence (NPMI)', 'Silhouette Score', 'ARI', 'Purity', 'NMI'])\n",
    "\n",
    "\n",
    "coh = coherence_score(docs, model, vectorizer_model)\n",
    "\n",
    "# play with seeing if you actually need topics param here\n",
    "sil = silhouette_metric(docs, embedding_model, model, topics)\n",
    "\n",
    "true_values = merged_df_subset['Original Factor']\n",
    "predicted_values = merged_df_subset['BERTopic Topic'] # NOTE THAT TOPIC -1 is included in the predicted_labels. Should we remove?!?!?!\n",
    "ari, purity, nmi = evaluation_metrics(true_values, predicted_values)\n",
    "\n",
    "metrics_df.loc[\"model 1\"] = [coh, sil, ari, purity, nmi]\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11283fc4-6351-4d03-9109-e8dd13557df8",
   "metadata": {},
   "source": [
    "## Comparing Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "74d3456a-7ad8-4991-851e-6390d081a547",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num Topics</th>\n",
       "      <th>Coherence (NPMI)</th>\n",
       "      <th>Silhouette Score</th>\n",
       "      <th>ARI</th>\n",
       "      <th>Purity</th>\n",
       "      <th>NMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Model 0 (min cluster: 2, min sample: 1)</th>\n",
       "      <td>33.0</td>\n",
       "      <td>0.260278</td>\n",
       "      <td>0.636757</td>\n",
       "      <td>0.296786</td>\n",
       "      <td>0.882979</td>\n",
       "      <td>0.739788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 1 (min cluster: 2, min sample: 2)</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.170295</td>\n",
       "      <td>0.791262</td>\n",
       "      <td>0.680537</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.836588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 2 (min cluster: 5, min sample: 5)</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.061421</td>\n",
       "      <td>0.874702</td>\n",
       "      <td>0.787245</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.874200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 3 (min cluster: 10, min sample: 10)</th>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.058653</td>\n",
       "      <td>0.783856</td>\n",
       "      <td>0.674083</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.815289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Num Topics  Coherence (NPMI)  \\\n",
       "Model 0 (min cluster: 2, min sample: 1)          33.0          0.260278   \n",
       "Model 1 (min cluster: 2, min sample: 2)          13.0          0.170295   \n",
       "Model 2 (min cluster: 5, min sample: 5)           8.0          0.061421   \n",
       "Model 3 (min cluster: 10, min sample: 10)         6.0         -0.058653   \n",
       "\n",
       "                                           Silhouette Score       ARI  \\\n",
       "Model 0 (min cluster: 2, min sample: 1)            0.636757  0.296786   \n",
       "Model 1 (min cluster: 2, min sample: 2)            0.791262  0.680537   \n",
       "Model 2 (min cluster: 5, min sample: 5)            0.874702  0.787245   \n",
       "Model 3 (min cluster: 10, min sample: 10)          0.783856  0.674083   \n",
       "\n",
       "                                             Purity       NMI  \n",
       "Model 0 (min cluster: 2, min sample: 1)    0.882979  0.739788  \n",
       "Model 1 (min cluster: 2, min sample: 2)    0.861702  0.836588  \n",
       "Model 2 (min cluster: 5, min sample: 5)    0.851064  0.874200  \n",
       "Model 3 (min cluster: 10, min sample: 10)  0.723404  0.815289  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run Functions/Functions.ipynb\n",
    "\n",
    "def get_model_comparisons(models):\n",
    "    # Create an empty DataFrame\n",
    "    comparison_df = pd.DataFrame(columns=['Num Topics', 'Coherence (NPMI)', 'Silhouette Score', 'ARI', 'Purity', 'NMI'])\n",
    "        \n",
    "    # Most popular model - Hugging Face: https://huggingface.co/sentence-transformers?sort_models=downloads#models\n",
    "    embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    \n",
    "    # remove stopwords/stop phrases containing 1 and 2 words\n",
    "    # NGRAM_RANGE is an important choice\n",
    "    stop_words = list(stopwords.words('english'))\n",
    "    vectorizer_model = CountVectorizer(ngram_range=(1, 2), stop_words=stop_words)\n",
    "\n",
    "\n",
    "    for index, mod in enumerate(models):\n",
    "        # Run custom model\n",
    "        model = run_custom_BERTopic(docs, embedding_model, vectorizer_model, min_cluster_size=mod['min_cluster_size'], min_samples=mod['min_samples'])\n",
    "        topics, probs = model.fit_transform(docs)\n",
    "        \n",
    "        topic_info_df = model.get_topic_info()\n",
    "        \n",
    "        num_topics = len(topic_info_df) - 1 # DOES NOT INCLUDE OUTLIERS TOPIC. ONLY COHERENT TOPICS\n",
    "\n",
    "        # now get evaluation metrics\n",
    "\n",
    "        ### Gather evaluation metrics\n",
    "        coh = coherence_score(docs, model, vectorizer_model)\n",
    "        \n",
    "        # play with seeing if you actually need topics param here\n",
    "        sil = silhouette_metric(docs, embedding_model, model, topics)\n",
    "        \n",
    "        true_values = df['Factor']\n",
    "        predicted_values = model.get_document_info(docs)['Topic'] # NOTE THAT TOPIC -1 is included in the predicted_labels. Should we remove?!?!?!\n",
    "        ari, purity, nmi = evaluation_metrics(true_values, predicted_values)\n",
    "        \n",
    "        comparison_df.loc[\"Model \" + str(index) + \" (min cluster: \" + str(mod['min_cluster_size']) + \", min sample: \" + str(mod['min_samples']) + \")\"] = [\n",
    "            num_topics, coh, sil, ari, purity, nmi]\n",
    "        \n",
    "    return comparison_df\n",
    "\n",
    "\n",
    "\n",
    "# List of models as dictionaries\n",
    "models = [\n",
    "    {\"min_cluster_size\": 2, \"min_samples\": 1},\n",
    "    {\"min_cluster_size\": 2, \"min_samples\": 2},\n",
    "    {\"min_cluster_size\": 5, \"min_samples\": 5},\n",
    "    {\"min_cluster_size\": 10, \"min_samples\": 10},\n",
    "]\n",
    "\n",
    "get_model_comparisons(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec8dfa7-b863-488f-87b0-a477253194a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
